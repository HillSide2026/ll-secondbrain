#!/usr/bin/env python3
"""
SB Execution Provisioning — SharePoint Setup

Verifies and provisions the SB Execution enclave:
- Folder structure (SB Execution/, DRAFTS, FINAL, RUN_LOGS, TEMPLATES)
- SB_* metadata columns on the document library
- Write permission verification

Usage:
    python setup_sb_execution.py --verify              # Read-only check
    python setup_sb_execution.py --provision            # Create missing items
    python setup_sb_execution.py --provision --verbose   # With debug logging

Requires:
- AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET env vars
- Azure app must have Sites.Manage.All (for column creation)
  and Files.ReadWrite.All (for folder creation)
"""

from __future__ import annotations

import argparse
import json
import logging
import os
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

import msal
import requests

log = logging.getLogger(__name__)

GRAPH_BASE = "https://graph.microsoft.com/v1.0"
REPO_ROOT = Path(__file__).resolve().parents[1]
OUTPUT_DIR = REPO_ROOT / "09_INBOX" / "_sources" / "sharepoint" / "discovery"

# Target drive — from Stage 3.8 action plan Fixed Target IDs
TARGET_DRIVE_ID = "b!aepYh7XvLkaJQFKWL0yhBXltDNo4pJRJpSPL-X-uZ-tNtZwBKQHoRYMyWJLL2q-P"

# Expected folder IDs (if already created)
EXPECTED_FOLDERS = {
    "execution_root": "017KHWIVBSTHL7MVN6YRE3YPVEOJHJHOW6",
    "DRAFTS": "017KHWIVDDUFGTNSDDYJGZF2V5OXBVFLOI",
    "FINAL": "017KHWIVHUT4KSP2ZNSVG2HVUUXL64OPGC",
    "RUN_LOGS": "017KHWIVEQGJFT2AVXQZE2WURHXZND5WOH",
    "TEMPLATES": "017KHWIVG2MPDGE6XXL5BKG2IWATADMOPQ",
}

# Column definitions per Stage 3.8 metadata contract
COLUMN_DEFINITIONS: List[Dict[str, Any]] = [
    {
        "name": "SB_Status",
        "displayName": "SB Status",
        "choice": {
            "allowTextEntry": False,
            "choices": [
                "DRAFT",
                "READY_FOR_REVIEW",
                "APPROVED_FOR_FINAL",
                "FINALIZED",
                "PROMOTION_INCOMPLETE",
                "REJECTED",
            ],
            "displayAs": "dropDownMenu",
        },
    },
    {
        "name": "SB_RunID",
        "displayName": "SB Run ID",
        "text": {"allowMultipleLines": False, "maxLength": 255},
    },
    {
        "name": "SB_TemplateVersion",
        "displayName": "SB Template Version",
        "text": {"allowMultipleLines": False, "maxLength": 50},
    },
    {
        "name": "SB_GeneratedAt",
        "displayName": "SB Generated At",
        "dateTime": {"displayAs": "default", "format": "dateTime"},
    },
    {
        "name": "SB_GeneratedBy",
        "displayName": "SB Generated By",
        "text": {"allowMultipleLines": False, "maxLength": 50},
    },
    {
        "name": "SB_ApprovedBy",
        "displayName": "SB Approved By",
        "text": {"allowMultipleLines": False, "maxLength": 255},
    },
    {
        "name": "SB_ApprovedAt",
        "displayName": "SB Approved At",
        "dateTime": {"displayAs": "default", "format": "dateTime"},
    },
    {
        "name": "SB_FinalizedAt",
        "displayName": "SB Finalized At",
        "dateTime": {"displayAs": "default", "format": "dateTime"},
    },
    {
        "name": "SB_FinalFileRef",
        "displayName": "SB Final File Ref",
        "text": {"allowMultipleLines": False, "maxLength": 500},
    },
]


def utc_now() -> str:
    return datetime.now(timezone.utc).isoformat(timespec="seconds")


def setup_logging(verbose: bool) -> None:
    logging.basicConfig(
        level=logging.DEBUG if verbose else logging.INFO,
        format="%(asctime)sZ [%(levelname)s] %(message)s",
        datefmt="%Y-%m-%dT%H:%M:%S",
    )


def require_env() -> tuple[str, str, str]:
    tenant = os.getenv("AZURE_TENANT_ID")
    client_id = os.getenv("AZURE_CLIENT_ID")
    client_secret = os.getenv("AZURE_CLIENT_SECRET")
    missing = [
        k for k, v in {
            "AZURE_TENANT_ID": tenant,
            "AZURE_CLIENT_ID": client_id,
            "AZURE_CLIENT_SECRET": client_secret,
        }.items()
        if not v
    ]
    if missing:
        raise RuntimeError(f"Missing environment variables: {missing}")
    return tenant, client_id, client_secret  # type: ignore[return-value]


class GraphClient:
    def __init__(self, tenant: str, client_id: str, client_secret: str):
        self.app = msal.ConfidentialClientApplication(
            client_id=client_id,
            authority=f"https://login.microsoftonline.com/{tenant}",
            client_credential=client_secret,
        )
        self._token: Optional[str] = None

    def token(self) -> str:
        if self._token:
            return self._token
        result = self.app.acquire_token_for_client(
            scopes=["https://graph.microsoft.com/.default"]
        )
        if "access_token" not in result:
            raise RuntimeError(f"Token failure: {result}")
        self._token = result["access_token"]
        return self._token

    def _headers(self) -> dict:
        return {"Authorization": f"Bearer {self.token()}"}

    def get(self, url: str, params: Optional[dict] = None) -> dict:
        r = requests.get(url, headers=self._headers(), params=params, timeout=60)
        if r.status_code >= 400:
            log.warning("GET %d: %s — %s", r.status_code, url, r.text[:500])
            return {"error": {"code": r.status_code, "message": r.text[:500]}}
        return r.json()

    def post(self, url: str, json_body: dict) -> dict:
        headers = {**self._headers(), "Content-Type": "application/json"}
        r = requests.post(url, headers=headers, json=json_body, timeout=60)
        if r.status_code >= 400:
            log.warning("POST %d: %s — %s", r.status_code, url, r.text[:500])
            return {"error": {"code": r.status_code, "message": r.text[:500]}}
        return r.json()

    def paged_get(self, url: str, params: Optional[dict] = None) -> List[dict]:
        items: List[dict] = []
        while url:
            payload = self.get(url, params=params)
            if "error" in payload:
                break
            items.extend(payload.get("value", []))
            url = payload.get("@odata.nextLink")
            params = None
        return items


# =============================
# Verification
# =============================


def verify_drive(graph: GraphClient) -> dict:
    """Check that target drive is accessible."""
    log.info("Verifying drive access: %s", TARGET_DRIVE_ID)
    resp = graph.get(f"{GRAPH_BASE}/drives/{TARGET_DRIVE_ID}")
    if "error" in resp:
        return {"accessible": False, "error": resp["error"]}
    return {
        "accessible": True,
        "name": resp.get("name"),
        "webUrl": resp.get("webUrl"),
        "driveType": resp.get("driveType"),
    }


def verify_folders(graph: GraphClient) -> Dict[str, dict]:
    """Check each expected folder by ID."""
    results = {}
    for name, folder_id in EXPECTED_FOLDERS.items():
        log.info("Checking folder %s (id=%s)...", name, folder_id)
        resp = graph.get(f"{GRAPH_BASE}/drives/{TARGET_DRIVE_ID}/items/{folder_id}")
        if "error" in resp:
            results[name] = {"found": False, "id": folder_id, "error": resp["error"]}
        else:
            results[name] = {
                "found": True,
                "id": folder_id,
                "name": resp.get("name"),
                "webUrl": resp.get("webUrl"),
                "childCount": resp.get("folder", {}).get("childCount"),
            }
    return results


def verify_columns(graph: GraphClient) -> Dict[str, dict]:
    """Check which SB_* columns exist on the library."""
    log.info("Checking columns on library...")
    columns = graph.paged_get(f"{GRAPH_BASE}/drives/{TARGET_DRIVE_ID}/list/columns")

    existing = {}
    for col in columns:
        name = col.get("name", "")
        if name.startswith("SB_"):
            col_type = "Unknown"
            if col.get("choice"):
                col_type = "Choice"
            elif col.get("dateTime"):
                col_type = "DateTime"
            elif col.get("personOrGroup"):
                col_type = "User"
            elif col.get("text"):
                col_type = "Text"
            existing[name] = {
                "id": col.get("id"),
                "type": col_type,
                "displayName": col.get("displayName"),
            }

    results = {}
    for col_def in COLUMN_DEFINITIONS:
        name = col_def["name"]
        if name in existing:
            results[name] = {"found": True, **existing[name]}
        else:
            results[name] = {"found": False}

    return results


def verify_write_permission(graph: GraphClient) -> dict:
    """Test write capability by attempting to create and delete a test file."""
    log.info("Testing write permission...")
    drafts_id = EXPECTED_FOLDERS["DRAFTS"]
    test_filename = "__write_test__.txt"
    test_url = (
        f"{GRAPH_BASE}/drives/{TARGET_DRIVE_ID}/items/{drafts_id}:/{test_filename}:/content"
    )

    # Try to upload a tiny test file
    headers = {
        "Authorization": f"Bearer {graph.token()}",
        "Content-Type": "text/plain",
    }
    r = requests.put(
        test_url, headers=headers, data=b"write test", timeout=30
    )
    if r.status_code >= 400:
        return {"writable": False, "error": r.text[:300]}

    # Clean up — delete the test file
    item_id = r.json().get("id")
    if item_id:
        delete_url = f"{GRAPH_BASE}/drives/{TARGET_DRIVE_ID}/items/{item_id}"
        del_headers = {"Authorization": f"Bearer {graph.token()}"}
        requests.delete(delete_url, headers=del_headers, timeout=30)
        log.info("Write test file cleaned up")

    return {"writable": True}


# =============================
# Provisioning
# =============================


def create_folder(graph: GraphClient, parent_id: str, folder_name: str) -> dict:
    """Create a folder under a parent item."""
    log.info("Creating folder: %s under %s", folder_name, parent_id)
    url = f"{GRAPH_BASE}/drives/{TARGET_DRIVE_ID}/items/{parent_id}/children"
    body = {
        "name": folder_name,
        "folder": {},
        "@microsoft.graph.conflictBehavior": "fail",
    }
    resp = graph.post(url, body)
    if "error" in resp:
        return {"created": False, "error": resp["error"]}
    return {
        "created": True,
        "id": resp.get("id"),
        "name": resp.get("name"),
        "webUrl": resp.get("webUrl"),
    }


def create_column(graph: GraphClient, col_def: dict) -> dict:
    """Create a column on the library's list."""
    name = col_def["name"]
    log.info("Creating column: %s", name)
    url = f"{GRAPH_BASE}/drives/{TARGET_DRIVE_ID}/list/columns"
    resp = graph.post(url, col_def)
    if "error" in resp:
        return {"created": False, "name": name, "error": resp["error"]}
    return {
        "created": True,
        "name": name,
        "id": resp.get("id"),
        "displayName": resp.get("displayName"),
    }


# =============================
# Main
# =============================


def run_verify(graph: GraphClient) -> dict:
    """Run all verification checks."""
    report: Dict[str, Any] = {"timestamp": utc_now(), "mode": "verify"}

    # Drive
    report["drive"] = verify_drive(graph)
    if not report["drive"].get("accessible"):
        log.error("Drive not accessible — cannot continue")
        return report

    # Folders
    report["folders"] = verify_folders(graph)
    folders_ok = all(f["found"] for f in report["folders"].values())

    # Columns
    report["columns"] = verify_columns(graph)
    columns_ok = all(c["found"] for c in report["columns"].values())

    # Write permission (only if folders exist)
    if folders_ok:
        report["write_permission"] = verify_write_permission(graph)
    else:
        report["write_permission"] = {"writable": False, "note": "Skipped — folders missing"}

    # Summary
    folder_count = sum(1 for f in report["folders"].values() if f["found"])
    column_count = sum(1 for c in report["columns"].values() if c["found"])
    report["summary"] = {
        "drive_accessible": report["drive"]["accessible"],
        "folders": f"{folder_count}/{len(EXPECTED_FOLDERS)}",
        "columns": f"{column_count}/{len(COLUMN_DEFINITIONS)}",
        "writable": report["write_permission"].get("writable", False),
        "ready": folders_ok and columns_ok and report["write_permission"].get("writable", False),
    }

    return report


def run_provision(graph: GraphClient, report: dict) -> dict:
    """Create missing folders and columns."""
    results: Dict[str, Any] = {"timestamp": utc_now(), "mode": "provision"}

    # Create missing folders
    folder_results = {}
    folders = report.get("folders", {})

    # If root doesn't exist, create it first
    if not folders.get("execution_root", {}).get("found"):
        root_result = create_folder(graph, "root", "SB Execution")
        folder_results["execution_root"] = root_result
        root_id = root_result.get("id", "")
    else:
        root_id = EXPECTED_FOLDERS["execution_root"]

    # Create subfolders under root
    for subfolder in ["DRAFTS", "FINAL", "RUN_LOGS", "TEMPLATES"]:
        if not folders.get(subfolder, {}).get("found"):
            if root_id:
                folder_results[subfolder] = create_folder(graph, root_id, subfolder)
            else:
                folder_results[subfolder] = {"created": False, "error": "No root folder"}

    results["folders"] = folder_results

    # Create missing columns
    column_results = {}
    columns = report.get("columns", {})
    for col_def in COLUMN_DEFINITIONS:
        name = col_def["name"]
        if not columns.get(name, {}).get("found"):
            column_results[name] = create_column(graph, col_def)

    results["columns"] = column_results

    return results


def print_report(report: dict) -> None:
    """Print human-readable verification report."""
    summary = report.get("summary", {})
    log.info("=== Verification Report ===")
    log.info("Drive accessible: %s", summary.get("drive_accessible"))

    if report["drive"].get("accessible"):
        log.info("  Library: %s", report["drive"].get("name"))
        log.info("  URL: %s", report["drive"].get("webUrl"))

    log.info("Folders: %s", summary.get("folders"))
    for name, info in report.get("folders", {}).items():
        status = "FOUND" if info.get("found") else "MISSING"
        log.info("  %s: %s", name, status)

    log.info("Columns: %s", summary.get("columns"))
    for name, info in report.get("columns", {}).items():
        status = "FOUND" if info.get("found") else "MISSING"
        extra = f" ({info.get('type')})" if info.get("found") else ""
        log.info("  %s: %s%s", name, status, extra)

    log.info("Write permission: %s", summary.get("writable"))
    log.info("Ready for live execution: %s", summary.get("ready"))


def main() -> None:
    parser = argparse.ArgumentParser(
        description="SB Execution provisioning — verify and create SharePoint structure",
    )
    parser.add_argument("--verify", action="store_true", help="Verify current state (read-only)")
    parser.add_argument("--provision", action="store_true", help="Create missing folders and columns")
    parser.add_argument("--verbose", action="store_true", help="Enable DEBUG logging")
    args = parser.parse_args()

    if not args.verify and not args.provision:
        parser.error("Specify --verify or --provision")

    setup_logging(args.verbose)

    tenant, client_id, client_secret = require_env()
    graph = GraphClient(tenant, client_id, client_secret)
    log.info("Token acquired")

    # Always verify first
    log.info("=== Phase 1: Verification ===")
    report = run_verify(graph)
    print_report(report)

    # Save verify report
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    report_path = OUTPUT_DIR / "setup_verify.json"
    report_path.write_text(json.dumps(report, indent=2) + "\n")
    log.info("Report saved: %s", report_path)

    if not args.provision:
        if report["summary"]["ready"]:
            log.info("=== All checks passed. Ready for live execution. ===")
            sys.exit(0)
        else:
            log.warning("=== Gaps detected. Run with --provision to fix. ===")
            sys.exit(1)

    # Provision
    if report["summary"]["ready"]:
        log.info("=== Already fully provisioned. Nothing to do. ===")
        sys.exit(0)

    if not report["drive"]["accessible"]:
        log.error("Cannot provision — drive not accessible. Check permissions.")
        sys.exit(2)

    log.info("=== Phase 2: Provisioning ===")
    provision_result = run_provision(graph, report)

    # Report provisioning results
    log.info("=== Provisioning Results ===")
    for name, info in provision_result.get("folders", {}).items():
        if info.get("created"):
            log.info("  Folder %s: CREATED (id=%s)", name, info.get("id"))
        else:
            log.error("  Folder %s: FAILED — %s", name, info.get("error"))

    for name, info in provision_result.get("columns", {}).items():
        if info.get("created"):
            log.info("  Column %s: CREATED (id=%s)", name, info.get("id"))
        else:
            log.error("  Column %s: FAILED — %s", name, info.get("error"))

    # Save provision report
    provision_path = OUTPUT_DIR / "setup_provision.json"
    provision_path.write_text(json.dumps(provision_result, indent=2) + "\n")
    log.info("Provision report saved: %s", provision_path)

    # Re-verify
    log.info("=== Phase 3: Re-verification ===")
    final_report = run_verify(graph)
    print_report(final_report)

    final_path = OUTPUT_DIR / "setup_final_verify.json"
    final_path.write_text(json.dumps(final_report, indent=2) + "\n")

    if final_report["summary"]["ready"]:
        log.info("=== Provisioning complete. Ready for live execution. ===")
        sys.exit(0)
    else:
        log.error("=== Provisioning incomplete. Review errors above. ===")
        sys.exit(3)


if __name__ == "__main__":
    main()
